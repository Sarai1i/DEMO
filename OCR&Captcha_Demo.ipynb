{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR-jqjIVqhW4",
        "outputId": "c3ca300c-7eb9-4d18-a3f5-b7e5063c2090",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr-ara is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install tesseract-ocr-ara"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wfNAUFlq6Ju",
        "outputId": "0a4588eb-3077-4f26-be42-8c8813558dcd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ4wWToWq8dA",
        "outputId": "c60fb44b-2fcc-49d1-8893-3c95993847df",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tesseract 4.1.1\n",
            " leptonica-1.82.0\n",
            "  libgif 5.1.9 : libjpeg 8d (libjpeg-turbo 2.1.1) : libpng 1.6.37 : libtiff 4.3.0 : zlib 1.2.11 : libwebp 1.2.2 : libopenjp2 2.4.0\n",
            " Found AVX2\n",
            " Found AVX\n",
            " Found FMA\n",
            " Found SSE\n",
            " Found libarchive 3.6.0 zlib/1.2.11 liblzma/5.2.5 bz2lib/1.0.8 liblz4/1.9.3 libzstd/1.4.8\n"
          ]
        }
      ],
      "source": [
        "!tesseract --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRnKo6QZrTOP",
        "outputId": "9fd0c2b9-7a24-4508-b192-279f03108675",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.13.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.7)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.6.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.6.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJKlhVTj002R",
        "outputId": "eecbbebf-9d4e-48b0-f284-515e28284b0c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pdf2image\n",
        "# Install Poppler for pdf2image\n",
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pdf2image import convert_from_path\n",
        "# from PIL import Image\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import pytesseract\n",
        "# import gradio as gr\n",
        "# import os\n",
        "\n",
        "# # Function to preprocess the image\n",
        "# def preprocess_image(image):\n",
        "#     image = np.array(image)\n",
        "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "#     binary = cv2.threshold(gray, 128, 255, cv2.THRESH _BINARY | cv2.THRESH_OTSU)  # Binarization\n",
        "#     return binary\n",
        "\n",
        "# # Function to check valid words\n",
        "# def is_valid_word(word):\n",
        "#     excluded_chars = {'.', '،', ')', '(', '-', '_', ':', ';', '!', '?', '\"', \"'\"}  # Excluded symbols\n",
        "#     if len(set(word)) <= 2 or any(char in excluded_chars for char in word):\n",
        "#         return False\n",
        "#     return True\n",
        "\n",
        "# # Function for OCR with confidence\n",
        "# def ocr_with_confidence_on_pdf(pdf_path, confidence_threshold=80):\n",
        "#     # Convert PDF to images\n",
        "#     images = convert_from_path(pdf_path)\n",
        "\n",
        "#     low_confidence_data = []\n",
        "\n",
        "#     # Process each page\n",
        "#     for page_num, image in enumerate(images, start=1):\n",
        "#         # Preprocess the image\n",
        "#         binary_image = preprocess_image(image)\n",
        "\n",
        "#         # Extract text using Tesseract\n",
        "#         data = pytesseract.image_to_data(\n",
        "#             Image.fromarray(binary_image),\n",
        "#             output_type=pytesseract.Output.DICT,\n",
        "#             lang=\"ara\"\n",
        "#         )\n",
        "\n",
        "#         for i, word in enumerate(data['text']):\n",
        "#             if word.strip() and is_valid_word(word):  # Exclude empty and invalid words\n",
        "#                 confidence = int(data['conf'][i])\n",
        "#                 x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
        "\n",
        "#                 # Crop and save low-confidence words as images\n",
        "#                 if confidence < confidence_threshold and confidence >= 0:\n",
        "#                     # Ensure valid word dimensions (avoid very small images)\n",
        "#                     if w > 20 and h > 20:  # Adjust threshold to filter out lines and artifacts\n",
        "#                         word_image = binary_image[y:y+h, x:x+w]  # Crop the word image\n",
        "#                         low_confidence_data.append((word, confidence, page_num, Image.fromarray(word_image)))\n",
        "\n",
        "#     # Return low-confidence words data\n",
        "#     return low_confidence_data\n",
        "\n",
        "# # Gradio interface\n",
        "# def feedback_interface(pdf_path):\n",
        "#     low_confidence_data = ocr_with_confidence_on_pdf(pdf_path)\n",
        "\n",
        "#     def get_feedback_interface():\n",
        "#         index = 0\n",
        "#         feedback_results = []\n",
        "\n",
        "#         def show_next():\n",
        "#             nonlocal index\n",
        "#             if index < len(low_confidence_data):\n",
        "#                 word, confidence, page, word_image = low_confidence_data[index]\n",
        "#                 index += 1\n",
        "#                 return word_image, f\"Word: {word} (Confidence: {confidence}%, Page: {page})\", gr.update(visible=False), \"\"\n",
        "#             else:\n",
        "#                 return None, \"No more words to review.\", gr.update(visible=False), \"\"\n",
        "\n",
        "#         def thumbs_up():\n",
        "#             return show_next()\n",
        "\n",
        "#         def thumbs_down():\n",
        "#             return gr.update(visible=True)\n",
        "\n",
        "#         def submit_correction(new_word):\n",
        "#             nonlocal index\n",
        "#             word, confidence, page, _ = low_confidence_data[index - 1]\n",
        "#             feedback_results.append((word, confidence, new_word))\n",
        "#             return show_next()\n",
        "\n",
        "#         return show_next, thumbs_up, thumbs_down, submit_correction\n",
        "\n",
        "#     show_next, thumbs_up, thumbs_down, submit_correction = get_feedback_interface()\n",
        "#     return show_next, thumbs_up, thumbs_down, submit_correction\n",
        "\n",
        "# with gr.Blocks() as demo:\n",
        "#     gr.Markdown(\"# Review Low Confidence Words in PDF\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         pdf_input = gr.File(label=\"Upload PDF File\")\n",
        "\n",
        "#     image_output = gr.Image(label=\"Word Image\")\n",
        "#     text_output = gr.Text(label=\"Word Details\")\n",
        "#     correction_input = gr.Textbox(label=\"Correct Word\", visible=False)\n",
        "\n",
        "#     with gr.Row():\n",
        "#         thumbs_up_button = gr.Button(\"👍 Correct\")\n",
        "#         thumbs_down_button = gr.Button(\"👎 Incorrect\")\n",
        "#         submit_button = gr.Button(\"Submit Correction\", visible=False)\n",
        "\n",
        "#     def on_file_upload(pdf):\n",
        "#         global show_next, thumbs_up, thumbs_down, submit_correction\n",
        "#         show_next, thumbs_up, thumbs_down, submit_correction = feedback_interface(pdf)\n",
        "#         return show_next()\n",
        "\n",
        "#     def on_thumbs_up():\n",
        "#         return thumbs_up()\n",
        "\n",
        "#     def on_thumbs_down():\n",
        "#         return thumbs_down()\n",
        "\n",
        "#     def on_submit_correction(new_word):\n",
        "#         return submit_correction(new_word)\n",
        "\n",
        "#     pdf_input.change(\n",
        "#         on_file_upload,\n",
        "#         inputs=[pdf_input],\n",
        "#         outputs=[image_output, text_output, correction_input, correction_input]\n",
        "#     )\n",
        "\n",
        "#     thumbs_up_button.click(\n",
        "#         on_thumbs_up,\n",
        "#         outputs=[image_output, text_output, correction_input, correction_input]\n",
        "#     )\n",
        "\n",
        "#     thumbs_down_button.click(\n",
        "#         on_thumbs_down,\n",
        "#         outputs=[correction_input]\n",
        "#     )\n",
        "\n",
        "#     submit_button.click(\n",
        "#         on_submit_correction,\n",
        "#         inputs=[correction_input],\n",
        "#         outputs=[image_output, text_output, correction_input, correction_input]\n",
        "#     )\n",
        "\n",
        "# demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "kjOS-Fdiy4Mf",
        "outputId": "1e522e1f-6426-4bb1-8cc1-6da09a1798c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-8-3d5b84007715>, line 13)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-3d5b84007715>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    binary = cv2.threshold(gray, 128, 255, cv2.THRESH _BINARY | cv2.THRESH_OTSU)  # Binarization\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "# Function to preprocess the image\n",
        "def preprocess_image(image):\n",
        "    image = np.array(image)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)  # Binarization\n",
        "    return binary\n",
        "\n",
        "# Function to check valid words\n",
        "def is_valid_word(word):\n",
        "    excluded_chars = {'.', '،', ')', '(', '-', '_', ':', ';', '!', '?', '\"', \"'\"}  # Excluded symbols\n",
        "    if len(set(word)) <= 2 or any(char in excluded_chars for char in word):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "# Function for OCR with confidence\n",
        "def ocr_with_confidence_on_pdf(pdf_path, confidence_threshold=80):\n",
        "    # Convert PDF to images\n",
        "    images = convert_from_path(pdf_path)\n",
        "\n",
        "    low_confidence_data = []\n",
        "\n",
        "    # Process each page\n",
        "    for page_num, image in enumerate(images, start=1):\n",
        "        # Preprocess the image\n",
        "        binary_image = preprocess_image(image)\n",
        "\n",
        "        # Extract text using Tesseract\n",
        "        data = pytesseract.image_to_data(\n",
        "            Image.fromarray(binary_image),\n",
        "            output_type=pytesseract.Output.DICT,\n",
        "            lang=\"ara\"\n",
        "        )\n",
        "\n",
        "        for i, word in enumerate(data['text']):\n",
        "            if word.strip() and is_valid_word(word):  # Exclude empty and invalid words\n",
        "                confidence = int(data['conf'][i])\n",
        "                x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
        "\n",
        "                # Crop and save low-confidence words as images\n",
        "                if confidence < confidence_threshold and confidence >= 0:\n",
        "                    # Ensure valid word dimensions (avoid very small images)\n",
        "                    if w > 20 and h > 20:  # Adjust threshold to filter out lines and artifacts\n",
        "                        word_image = binary_image[y:y+h, x:x+w]  # Crop the word image\n",
        "                        low_confidence_data.append((word, confidence, page_num, Image.fromarray(word_image)))\n",
        "\n",
        "    # Return low-confidence words data\n",
        "    return low_confidence_data\n",
        "\n",
        "# Gradio interface\n",
        "def feedback_interface(pdf_path):\n",
        "    low_confidence_data = ocr_with_confidence_on_pdf(pdf_path)\n",
        "\n",
        "    def get_feedback_interface():\n",
        "        index = 0\n",
        "        feedback_results = []\n",
        "\n",
        "        def show_next():\n",
        "            nonlocal index\n",
        "            if index < len(low_confidence_data):\n",
        "                word, confidence, page, word_image = low_confidence_data[index]\n",
        "                index += 1\n",
        "                return word_image, f\"Word: {word} (Confidence: {confidence}%, Page: {page})\", gr.update(visible=False), \"\"\n",
        "            else:\n",
        "                return None, \"No more words to review.\", gr.update(visible=False), \"\"\n",
        "\n",
        "        def thumbs_up():\n",
        "            return show_next()\n",
        "\n",
        "        def thumbs_down():\n",
        "            return gr.update(visible=True)\n",
        "\n",
        "        def submit_correction(new_word):\n",
        "            nonlocal index\n",
        "            word, confidence, page, _ = low_confidence_data[index - 1]\n",
        "            feedback_results.append((word, confidence, new_word))\n",
        "            return show_next()\n",
        "\n",
        "        return show_next, thumbs_up, thumbs_down, submit_correction\n",
        "\n",
        "    show_next, thumbs_up, thumbs_down, submit_correction = get_feedback_interface()\n",
        "    return show_next, thumbs_up, thumbs_down, submit_correction\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Review Low Confidence Words in PDF\")\n",
        "\n",
        "    with gr.Row():\n",
        "        pdf_input = gr.File(label=\"Upload PDF File\")\n",
        "\n",
        "    image_output = gr.Image(label=\"Word Image\")\n",
        "    text_output = gr.Text(label=\"Word Details\")\n",
        "    correction_input = gr.Textbox(label=\"Correct Word\", visible=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        thumbs_up_button = gr.Button(\"👍 Correct\")\n",
        "        thumbs_down_button = gr.Button(\"👎 Incorrect\")\n",
        "        submit_button = gr.Button(\"Submit Correction\", visible=False)\n",
        "\n",
        "    def on_file_upload(pdf):\n",
        "        global show_next, thumbs_up, thumbs_down, submit_correction\n",
        "        show_next, thumbs_up, thumbs_down, submit_correction = feedback_interface(pdf)\n",
        "        return show_next()\n",
        "\n",
        "    def on_thumbs_up():\n",
        "        return thumbs_up()\n",
        "\n",
        "    def on_thumbs_down():\n",
        "        return thumbs_down()\n",
        "\n",
        "    def on_submit_correction(new_word):\n",
        "        return submit_correction(new_word)\n",
        "\n",
        "    pdf_input.change(\n",
        "        on_file_upload,\n",
        "        inputs=[pdf_input],\n",
        "        outputs=[image_output, text_output, correction_input, correction_input]\n",
        "    )\n",
        "\n",
        "    thumbs_up_button.click(\n",
        "        on_thumbs_up,\n",
        "        outputs=[image_output, text_output, correction_input, correction_input]\n",
        "    )\n",
        "\n",
        "    thumbs_down_button.click(\n",
        "        on_thumbs_down,\n",
        "        outputs=[correction_input]\n",
        "    )\n",
        "\n",
        "    submit_button.click(\n",
        "        on_submit_correction,\n",
        "        inputs=[correction_input],\n",
        "        outputs=[image_output, text_output, correction_input, correction_input]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "B3urTJcSdFv0",
        "outputId": "b5f5e619-5302-45eb-9fd0-a524d368bb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://96998dfe064f45cc3f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://96998dfe064f45cc3f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7IADg_Ezbng"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}